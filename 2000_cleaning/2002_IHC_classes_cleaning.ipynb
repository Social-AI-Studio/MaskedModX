{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "20fJ8J891X_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H_FpuOpAXgqu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "id": "vDaPkpBkUdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "03IvRW_dUbFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create directory to store cleaned data"
      ],
      "metadata": {
        "id": "hHaZjpoP_uyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/datasets/cleaning', exist_ok=True)"
      ],
      "metadata": {
        "id": "ngsotMhY_xCh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets"
      ],
      "metadata": {
        "id": "EXHWFJW23GXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get lists of files in **/content/drive/MyDrive/datasets/IHC_classes_gpt-3.5-turbo-0301** and **/content/drive/MyDrive/datasets/IHC_classes_gpt-3.5-turbo-0613** directories"
      ],
      "metadata": {
        "id": "nkTR9Wm8hmXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in directories. via\n",
        "# https://www.geeksforgeeks.org/python-list-files-in-a-directory/\n",
        "dir_0301 = '/content/drive/MyDrive/datasets/IHC_classes_gpt-3.5-turbo-0301'\n",
        "file_list_0301 = os.listdir(dir_0301)\n",
        "file_list_0301 = sorted(file_list_0301)\n",
        "dir_0613 = '/content/drive/MyDrive/datasets/IHC_classes_gpt-3.5-turbo-0613'\n",
        "file_list_0613 = os.listdir(dir_0613)\n",
        "file_list_0613 = sorted(file_list_0613)"
      ],
      "metadata": {
        "id": "ZP3sW0ri3i8W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate files in file lists into one Pandas DataFrame for each list"
      ],
      "metadata": {
        "id": "auNvUaO_hsXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and concatenate multiple files. via\n",
        "# https://stackoverflow.com/a/21232849\n",
        "IHC_classes_0301 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0301, '/', file)), sep='\\t') for file in\n",
        "     file_list_0301],\n",
        "    axis=1)\n",
        "IHC_classes_0613 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0613, '/', file)), sep='\\t') for file in\n",
        "     file_list_0613],\n",
        "    axis=1)\n",
        "# Drop duplicate columns. via\n",
        "# https://www.geeksforgeeks.org/\n",
        "# how-to-find-drop-duplicate-columns-in-a-pandas-dataframe/\n",
        "IHC_classes_0301 = IHC_classes_0301.T.drop_duplicates().T\n",
        "IHC_classes_0613 = IHC_classes_0613.T.drop_duplicates().T"
      ],
      "metadata": {
        "id": "GF9argYz4E2e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to get the distribution of responses"
      ],
      "metadata": {
        "id": "69Epu2wbcWeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_responses_distribution(df, model):\n",
        "    # Value counts across multiple columns. via\n",
        "    # https://stackoverflow.com/a/61565732\n",
        "    responses_distribution = df.iloc[:, 2:].stack().value_counts()\n",
        "    # Convert value_counts output to dataframe format. via\n",
        "    # https://stackoverflow.com/a/47136484\n",
        "    responses_distribution = responses_distribution.rename_axis(\n",
        "        'Responses').reset_index(name='Count')\n",
        "    responses_distribution.to_csv(\n",
        "        f'/content/drive/MyDrive/datasets/cleaning/'\n",
        "        f'IHC_classes_responses_distribution_{model}.csv',\n",
        "        index=False)\n",
        "    # Count null values in dataframe. via\n",
        "    # https://stackoverflow.com/questions/26266362/\n",
        "    # how-do-i-count-the-nan-values-in-a-column-in-pandas-dataframe#\n",
        "    # comment74712638_26266451\n",
        "    print('Number of unusable responses is:')\n",
        "    print(df.iloc[:, 2:].isna().sum().sum())"
      ],
      "metadata": {
        "id": "6Bnv7CcTfnXB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(IHC_classes_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(IHC_classes_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "z5FC1as2ZPu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean valid responses to conform to how the data was coded, e.g., `explicit_hate` if `A: Yes, explicit hate speech.`"
      ],
      "metadata": {
        "id": "FahgjNac-tpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remap values. via\n",
        "# https://stackoverflow.com/a/64231348\n",
        "def remap(x):\n",
        "    x = x.lower()\n",
        "    if 'a: yes, explicit hate speech' in x:\n",
        "        return 'explicit_hate'\n",
        "    elif 'b: yes, implicit hate speech' in x:\n",
        "        return 'implicit_hate'\n",
        "    elif 'c: not hate speech' in x:\n",
        "        return 'not_hate'\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "IHC_classes_0301.iloc[:, 2:] = IHC_classes_0301.iloc[:, 2:].applymap(\n",
        "    lambda x: remap(x))"
      ],
      "metadata": {
        "id": "RGFAdmxOe3Ag"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(IHC_classes_0301, 'gpt-3.5-turbo-0301')"
      ],
      "metadata": {
        "id": "rUbsd3jq3ZZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean the remaining valid responses to conform to how the data was coded, e.g., `not_hate` if `A: not hate speech.` (not remapped in previous round due to mismatched alphabetical choice, should be `C: not hate speech.`)"
      ],
      "metadata": {
        "id": "XyokVATdBO7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remap values. via\n",
        "# https://stackoverflow.com/a/64231348\n",
        "def remap_again(x):\n",
        "    if 'not hate speech' in x:\n",
        "        return 'not_hate'\n",
        "    elif 'yes, implicit hate speech' in x:\n",
        "        return 'implicit_hate'\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "IHC_classes_0301.iloc[:, 2:] = IHC_classes_0301.iloc[:, 2:].applymap(\n",
        "    lambda x: remap_again(x))"
      ],
      "metadata": {
        "id": "rawqRCTcrCSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(IHC_classes_0301, 'gpt-3.5-turbo-0301')"
      ],
      "metadata": {
        "id": "crunOh_HAT-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save cleaned responses"
      ],
      "metadata": {
        "id": "pwThwBglBf5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IHC_classes_0301.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'IHC_classes_predictions_cleaned_gpt-3.5-turbo-0301.tsv',\n",
        "    sep='\\t', index=False)\n",
        "IHC_classes_0613.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'IHC_classes_predictions_cleaned_gpt-3.5-turbo-0613.tsv',\n",
        "    sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "FRyEON_YvKRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}