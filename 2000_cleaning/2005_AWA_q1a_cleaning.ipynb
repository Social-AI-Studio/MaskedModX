{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20fJ8J891X_-"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_FpuOpAXgqu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDaPkpBkUdNj"
      },
      "source": [
        "# Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03IvRW_dUbFb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create directory to store cleaned data"
      ],
      "metadata": {
        "id": "v-gfMh6NiV-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/datasets/cleaning', exist_ok=True)"
      ],
      "metadata": {
        "id": "d3SOcR1UiVjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXHWFJW23GXl"
      },
      "source": [
        "# Import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get lists of files in **/content/drive/MyDrive/datasets/AWA_q1a_gpt-3.5-turbo-0301** and **/content/drive/MyDrive/datasets/AWA_q1a_gpt-3.5-turbo-0613** directories"
      ],
      "metadata": {
        "id": "Q98jpicpevVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP3sW0ri3i8W"
      },
      "outputs": [],
      "source": [
        "# List all files in directories. via\n",
        "# https://www.geeksforgeeks.org/python-list-files-in-a-directory/\n",
        "dir_0301 = '/content/drive/MyDrive/datasets/AWA_q1a_gpt-3.5-turbo-0301'\n",
        "file_list_0301 = os.listdir(dir_0301)\n",
        "file_list_0301 = sorted(file_list_0301)\n",
        "dir_0613 = '/content/drive/MyDrive/datasets/AWA_q1a_gpt-3.5-turbo-0613'\n",
        "file_list_0613 = os.listdir(dir_0613)\n",
        "file_list_0613 = sorted(file_list_0613)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate files in file lists into one Pandas DataFrame for each list"
      ],
      "metadata": {
        "id": "h9lIm9kLeziV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF9argYz4E2e"
      },
      "outputs": [],
      "source": [
        "# Import and concatenate multiple files. via\n",
        "# https://stackoverflow.com/a/21232849\n",
        "AWA_q1a_0301 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0301, '/', file)), sep='\\t') for file in\n",
        "     file_list_0301],\n",
        "    axis=1)\n",
        "AWA_q1a_0613 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0613, '/', file)), sep='\\t') for file in\n",
        "     file_list_0613],\n",
        "    axis=1)\n",
        "# Drop duplicate columns. via\n",
        "# https://www.geeksforgeeks.org/\n",
        "# how-to-find-drop-duplicate-columns-in-a-pandas-dataframe/\n",
        "AWA_q1a_0301 = AWA_q1a_0301.T.drop_duplicates().T\n",
        "AWA_q1a_0613 = AWA_q1a_0613.T.drop_duplicates().T"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to get the distribution of responses"
      ],
      "metadata": {
        "id": "SG8skNQ0qUxC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgqMuLelU33W"
      },
      "outputs": [],
      "source": [
        "def get_responses_distribution(df, model):\n",
        "    # Value counts across multiple columns. via\n",
        "    # https://stackoverflow.com/a/61565732\n",
        "    responses_distribution = df.iloc[:, 1:].stack().value_counts()\n",
        "    # Convert value_counts output to dataframe format. via\n",
        "    # https://stackoverflow.com/a/47136484\n",
        "    responses_distribution = responses_distribution.rename_axis(\n",
        "        'Responses').reset_index(name='Count')\n",
        "    responses_distribution.to_csv(\n",
        "        f'/content/drive/MyDrive/datasets/cleaning/'\n",
        "        f'AWA_q1a_responses_distribution_{model}.csv',\n",
        "        index=False)\n",
        "    # Count null values in dataframe. via\n",
        "    # https://stackoverflow.com/questions/26266362/\n",
        "    # how-do-i-count-the-nan-values-in-a-column-in-pandas-dataframe#\n",
        "    # comment74712638_26266451\n",
        "    print('Number of unusable responses is:')\n",
        "    print(df.iloc[:, 1:].isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2RF164oVB9V"
      },
      "outputs": [],
      "source": [
        "get_responses_distribution(AWA_q1a_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(AWA_q1a_0613, 'gpt-3.5-turbo-0613')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean valid responses to conform to how the data was coded, e.g., `5` if `Answer: 5`"
      ],
      "metadata": {
        "id": "O2suUAjdudrO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuoeV_i83yfR"
      },
      "outputs": [],
      "source": [
        "def remap(x):\n",
        "    # Determine if string only contains one digit. via\n",
        "    # https://stackoverflow.com/a/39799113\n",
        "    # Return True/False when using Regex. via\n",
        "    # https://stackoverflow.com/a/6577018\n",
        "    if bool(re.search(\"^\\D*1\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*1.0\\D*$\", str(x))):\n",
        "        return str(1)\n",
        "    elif bool(re.search(\"^\\D*2\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*2.0\\D*$\", str(x))):\n",
        "        return str(2)\n",
        "    elif bool(re.search(\"^\\D*3\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*3.0\\D*$\", str(x))):\n",
        "        return str(3)\n",
        "    elif bool(re.search(\"^\\D*4\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*4.0\\D*$\", str(x))):\n",
        "        return str(4)\n",
        "    elif bool(re.search(\"^\\D*5\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*5.0\\D*$\", str(x))):\n",
        "        return str(5)\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "AWA_q1a_0301.iloc[:, 1:] = AWA_q1a_0301.iloc[:, 1:].applymap(\n",
        "    lambda x: remap(x))\n",
        "AWA_q1a_0613.iloc[:, 1:] = AWA_q1a_0613.iloc[:, 1:].applymap(\n",
        "    lambda x: remap(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0zoIy0hetr1"
      },
      "outputs": [],
      "source": [
        "get_responses_distribution(AWA_q1a_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(AWA_q1a_0613, 'gpt-3.5-turbo-0613')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove invalid responses"
      ],
      "metadata": {
        "id": "IP2Z2UpSu91E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUJDlBTdikPT"
      },
      "outputs": [],
      "source": [
        "def remap_again(x):\n",
        "    if 'cannot provide an answer' in x:\n",
        "        return None\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "AWA_q1a_0301.iloc[:, 1:] = AWA_q1a_0301.iloc[:, 1:].applymap(\n",
        "    lambda x: remap_again(x))\n",
        "AWA_q1a_0613.iloc[:, 1:] = AWA_q1a_0613.iloc[:, 1:].applymap(\n",
        "    lambda x: remap_again(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egbF7PXet7nK"
      },
      "outputs": [],
      "source": [
        "get_responses_distribution(AWA_q1a_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(AWA_q1a_0613, 'gpt-3.5-turbo-0613')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listwise deletion of cases with invalid responses"
      ],
      "metadata": {
        "id": "i3R9oXpGwa-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select rows with null values. via\n",
        "# https://stackoverflow.com/a/14247708\n",
        "todrop = AWA_q1a_0301[AWA_q1a_0301[AWA_q1a_0301.columns[1:]].isna().any(axis=1)]['tweet'].tolist()\n",
        "# Drop rows where column values match any list element. via\n",
        "# https://stackoverflow.com/a/27965417\n",
        "AWA_q1a_0301 = AWA_q1a_0301[~AWA_q1a_0301['tweet'].isin(todrop)]\n",
        "AWA_q1a_0301.reset_index(drop=True, inplace=True)\n",
        "AWA_q1a_0613 = AWA_q1a_0613[~AWA_q1a_0613['tweet'].isin(todrop)]\n",
        "AWA_q1a_0613.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "FbLMAzltFwdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save cleaned responses"
      ],
      "metadata": {
        "id": "SrRSTNY2vfz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRyEON_YvKRM"
      },
      "outputs": [],
      "source": [
        "AWA_q1a_0301.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'AWA_q1a_predictions_cleaned_gpt-3.5-turbo-0301.tsv',\n",
        "    sep='\\t', index=False)\n",
        "AWA_q1a_0613.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'AWA_q1a_predictions_cleaned_gpt-3.5-turbo-0613.tsv',\n",
        "    sep='\\t', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}