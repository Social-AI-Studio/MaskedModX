{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "20fJ8J891X_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H_FpuOpAXgqu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "id": "vDaPkpBkUdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "03IvRW_dUbFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create directory to store cleaned data"
      ],
      "metadata": {
        "id": "vlUMvYAXG3dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/datasets/cleaning', exist_ok=True)"
      ],
      "metadata": {
        "id": "E90zCvCGG5QA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets"
      ],
      "metadata": {
        "id": "EXHWFJW23GXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get lists of files in **/content/drive/MyDrive/datasets/SBIC_gpt-3.5-turbo-0301** and **/content/drive/MyDrive/datasets/SBIC_gpt-3.5-turbo-0613** directories"
      ],
      "metadata": {
        "id": "wLHuu_0YNw8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in directories. via\n",
        "# https://www.geeksforgeeks.org/python-list-files-in-a-directory/\n",
        "dir_0301 = '/content/drive/MyDrive/datasets/SBIC_gpt-3.5-turbo-0301'\n",
        "file_list_0301 = os.listdir(dir_0301)\n",
        "file_list_0301 = sorted(file_list_0301)\n",
        "dir_0613 = '/content/drive/MyDrive/datasets/SBIC_gpt-3.5-turbo-0613'\n",
        "file_list_0613 = os.listdir(dir_0613)\n",
        "file_list_0613 = sorted(file_list_0613)"
      ],
      "metadata": {
        "id": "ZP3sW0ri3i8W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate files in file lists into one Pandas DataFrame for each list"
      ],
      "metadata": {
        "id": "_RDF4rFbE-Cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and concatenate multiple files. via\n",
        "# https://stackoverflow.com/a/21232849\n",
        "SBIC_0301 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0301, '/', file)), sep='\\t') for file in\n",
        "     file_list_0301],\n",
        "    axis=1)\n",
        "SBIC_0613 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0613, '/', file)), sep='\\t') for file in\n",
        "     file_list_0613],\n",
        "    axis=1)\n",
        "# Drop duplicate columns. via\n",
        "# https://www.geeksforgeeks.org/\n",
        "# how-to-find-drop-duplicate-columns-in-a-pandas-dataframe/\n",
        "SBIC_0301 = SBIC_0301.T.drop_duplicates().T\n",
        "SBIC_0613 = SBIC_0613.T.drop_duplicates().T"
      ],
      "metadata": {
        "id": "GF9argYz4E2e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to get the distribution of responses"
      ],
      "metadata": {
        "id": "COldB-qzFKZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_responses_distribution(df, model):\n",
        "    # Value counts across multiple columns. via\n",
        "    # https://stackoverflow.com/a/61565732\n",
        "    responses_distribution = df.iloc[:, 15:].stack().value_counts()\n",
        "    # Convert value_counts output to dataframe format. via\n",
        "    # https://stackoverflow.com/a/47136484\n",
        "    responses_distribution = responses_distribution.rename_axis(\n",
        "        'Responses').reset_index(name='Count')\n",
        "    responses_distribution.to_csv(\n",
        "        f'/content/drive/MyDrive/datasets/cleaning/'\n",
        "        f'SBIC_responses_distribution_{model}.csv',\n",
        "        index=False)\n",
        "    # Count null values in dataframe. via\n",
        "    # https://stackoverflow.com/questions/26266362/\n",
        "    # how-do-i-count-the-nan-values-in-a-column-in-pandas-dataframe#\n",
        "    # comment74712638_26266451\n",
        "    print('Number of unusable responses is:')\n",
        "    print(df.iloc[:, 15:].isna().sum().sum())"
      ],
      "metadata": {
        "id": "-MNIp_pkj4Q0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(SBIC_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(SBIC_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "rcSbNeJwbv4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove unsuccessful persona priming"
      ],
      "metadata": {
        "id": "I59m3K-t4trA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rm_failed(x):\n",
        "    x = str(x)\n",
        "    x = x.lower()\n",
        "    if 'as an ai language model' in x or 'as a language model' in x:\n",
        "        return None\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "cols = list(range(15, 79))\n",
        "cols.remove(62) # predicted_q1a_labels_base\n",
        "SBIC_0301.iloc[:, cols] = SBIC_0301.iloc[:, cols].applymap(\n",
        "    lambda x: rm_failed(x))\n",
        "SBIC_0613.iloc[:, cols] = SBIC_0613.iloc[:, cols].applymap(\n",
        "    lambda x: rm_failed(x))"
      ],
      "metadata": {
        "id": "jJZfNrQb4v9f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(SBIC_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(SBIC_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "ra3lTz0V64et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean valid responses to conform to how the data was coded, e.g., `1.0` if `A: Yes, this could be offensive.`"
      ],
      "metadata": {
        "id": "791hraRn_8wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remap(x):\n",
        "    if x is not None and \\\n",
        "    'a: yes, this could be offensive' in x.lower():\n",
        "        return '1.0'\n",
        "    elif x is not None and \\\n",
        "    'b: maybe, i\\'m not sure' in x.lower():\n",
        "        return '0.5'\n",
        "    elif x is not None and \\\n",
        "    'c: no, this is harmless' in x.lower():\n",
        "        return '0.0'\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "SBIC_0301.iloc[:, 15:] = SBIC_0301.iloc[:, 15:].applymap(lambda x: remap(x))\n",
        "SBIC_0613.iloc[:, 15:] = SBIC_0613.iloc[:, 15:].applymap(lambda x: remap(x))"
      ],
      "metadata": {
        "id": "WYvDq-t48TeQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(SBIC_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(SBIC_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "GrrKiwtFj0nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean the remaining valid responses to conform to how the data was coded, e.g., `0.0` if `No, this is harmless.` (not remapped in previous round due to absent alphabetical choice)"
      ],
      "metadata": {
        "id": "xaDyy6_8jsT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remap(x):\n",
        "    if x is not None and \\\n",
        "    'yes, this could be offensive' in x.lower():\n",
        "        return '1.0'\n",
        "    elif x is not None and \\\n",
        "    'no, this is harmless' in x.lower():\n",
        "        return '0.0'\n",
        "    elif str(x) in {'1.0', '0.5', '0.0'}:\n",
        "        return x\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "SBIC_0301.iloc[:, 15:] = SBIC_0301.iloc[:, 15:].applymap(lambda x: remap(x))\n",
        "SBIC_0613.iloc[:, 15:] = SBIC_0613.iloc[:, 15:].applymap(lambda x: remap(x))"
      ],
      "metadata": {
        "id": "9HXqOhK7jo8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(SBIC_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(SBIC_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "pBaZKyrykuMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listwise deletion of cases with invalid responses"
      ],
      "metadata": {
        "id": "20HrhPPpmeJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select rows with null values. via\n",
        "# https://stackoverflow.com/a/14247708\n",
        "todrop = SBIC_0301[SBIC_0301[SBIC_0301.columns[15:]].isna().any(axis=1)]['post'].tolist()\n",
        "# Drop rows where column values match any list element. via\n",
        "# https://stackoverflow.com/a/27965417\n",
        "SBIC_0301 = SBIC_0301[~SBIC_0301['post'].isin(todrop)]\n",
        "SBIC_0301.reset_index(drop=True, inplace=True)\n",
        "SBIC_0613 = SBIC_0613[~SBIC_0613['post'].isin(todrop)]\n",
        "SBIC_0613.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "2W48ipuE5hAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save cleaned responses"
      ],
      "metadata": {
        "id": "FNWKWPW2_uv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SBIC_0301.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'SBIC_predictions_cleaned_gpt-3.5-turbo-0301.tsv',\n",
        "    sep='\\t', index=False)\n",
        "SBIC_0613.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'SBIC_predictions_cleaned_gpt-3.5-turbo-0613.tsv',\n",
        "    sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "FRyEON_YvKRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}