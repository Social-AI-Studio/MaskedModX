{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "20fJ8J891X_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H_FpuOpAXgqu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "id": "vDaPkpBkUdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "03IvRW_dUbFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create directory to store cleaned data"
      ],
      "metadata": {
        "id": "UH3Tr2qvohGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/datasets/cleaning', exist_ok=True)"
      ],
      "metadata": {
        "id": "K361ueYhogm2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets"
      ],
      "metadata": {
        "id": "EXHWFJW23GXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get lists of files in **/content/drive/MyDrive/datasets/POPQUORN_gpt-3.5-turbo-0301** and **/content/drive/MyDrive/datasets/POPQUORN_gpt-3.5-turbo-0613** directories"
      ],
      "metadata": {
        "id": "w3QykWMWpCU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in directories.\n",
        "# via https://www.geeksforgeeks.org/python-list-files-in-a-directory/\n",
        "dir_0301 = '/content/drive/MyDrive/datasets/POPQUORN_gpt-3.5-turbo-0301'\n",
        "file_list_0301 = os.listdir(dir_0301)\n",
        "file_list_0301 = sorted(file_list_0301)\n",
        "dir_0613 = '/content/drive/MyDrive/datasets/POPQUORN_gpt-3.5-turbo-0613'\n",
        "file_list_0613 = os.listdir(dir_0613)\n",
        "file_list_0613 = sorted(file_list_0613)"
      ],
      "metadata": {
        "id": "ZP3sW0ri3i8W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate files in file lists into one Pandas DataFrame for each list"
      ],
      "metadata": {
        "id": "itux2irnpKCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and concatenate multiple files. via\n",
        "# https://stackoverflow.com/a/21232849\n",
        "POPQUORN_0301 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0301, '/', file)), sep='\\t') for file in\n",
        "     file_list_0301],\n",
        "    axis=1)\n",
        "POPQUORN_0613 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0613, '/', file)), sep='\\t') for file in\n",
        "     file_list_0613],\n",
        "    axis=1)\n",
        "# Drop duplicate columns. via\n",
        "# https://www.geeksforgeeks.org/\n",
        "# how-to-find-drop-duplicate-columns-in-a-pandas-dataframe/\n",
        "POPQUORN_0301 = POPQUORN_0301.T.drop_duplicates().T\n",
        "POPQUORN_0613 = POPQUORN_0613.T.drop_duplicates().T"
      ],
      "metadata": {
        "id": "GF9argYz4E2e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to get the distribution of responses"
      ],
      "metadata": {
        "id": "DbPBUsslpPpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_responses_distribution(df, model):\n",
        "    # Value counts across multiple columns. via\n",
        "    # https://stackoverflow.com/a/61565732\n",
        "    responses_distribution = df.iloc[:, 1:].stack().value_counts()\n",
        "    # Convert value_counts output to dataframe format. via\n",
        "    # https://stackoverflow.com/a/47136484\n",
        "    responses_distribution = responses_distribution.rename_axis(\n",
        "        'Responses').reset_index(name='Count')\n",
        "    responses_distribution.to_csv(\n",
        "        f'/content/drive/MyDrive/datasets/cleaning/'\n",
        "        f'POPQUORN_responses_distribution_{model}.csv',\n",
        "        index=False)\n",
        "    # Count null values in dataframe. via\n",
        "    # https://stackoverflow.com/questions/26266362/\n",
        "    # how-do-i-count-the-nan-values-in-a-column-in-pandas-dataframe#\n",
        "    # comment74712638_26266451\n",
        "    print('Number of unusable responses is:')\n",
        "    print(df.iloc[:, 1:].isna().sum().sum())"
      ],
      "metadata": {
        "id": "6Bnv7CcTfnXB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(POPQUORN_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(POPQUORN_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "JUH6cE6RKBZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove unsuccessful persona priming"
      ],
      "metadata": {
        "id": "aLZuJ4IJgxdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rm_failed(x):\n",
        "    x = str(x)\n",
        "    x = x.lower()\n",
        "    if 'as an ai language model' in x or 'as a language model' in x:\n",
        "        return None\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "cols = list(range(31))\n",
        "cols.remove(0) # tweet\n",
        "cols.remove(16) # predicted_scores_base\n",
        "POPQUORN_0301.iloc[:, cols] = POPQUORN_0301.iloc[:, cols].applymap(\n",
        "    lambda x: rm_failed(x))\n",
        "POPQUORN_0613.iloc[:, cols] = POPQUORN_0613.iloc[:, cols].applymap(\n",
        "    lambda x: rm_failed(x))"
      ],
      "metadata": {
        "id": "2sgd3m8DgyYa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(POPQUORN_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(POPQUORN_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "K8ri2LAVg0RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean valid responses to conform to how the data was coded, e.g., `1` if `1. not offensive at all.`"
      ],
      "metadata": {
        "id": "cqUriEjb1BMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remap(x):\n",
        "    # Determine if string only contains one digit. via\n",
        "    # https://stackoverflow.com/a/39799113\n",
        "    # Return True/False when using Regex. via\n",
        "    # https://stackoverflow.com/questions/6576962/\n",
        "    # python-regular-expressions-return-true-false\n",
        "    if bool(re.search(\"^\\D*1\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*1.0\\D*$\", str(x))):\n",
        "        return str(1)\n",
        "    elif bool(re.search(\"^\\D*2\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*2.0\\D*$\", str(x))):\n",
        "        return str(2)\n",
        "    elif bool(re.search(\"^\\D*3\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*3.0\\D*$\", str(x))):\n",
        "        return str(3)\n",
        "    elif bool(re.search(\"^\\D*4\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*4.0\\D*$\", str(x))):\n",
        "        return str(4)\n",
        "    elif bool(re.search(\"^\\D*5\\D*$\", str(x))) or bool(\n",
        "            re.search(\"^\\D*5.0\\D*$\", str(x))):\n",
        "        return str(5)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "POPQUORN_0301.iloc[:, 1:] = POPQUORN_0301.iloc[:, 1:].applymap(\n",
        "    lambda x: remap(x))\n",
        "POPQUORN_0613.iloc[:, 1:] = POPQUORN_0613.iloc[:, 1:].applymap(\n",
        "    lambda x: remap(x))"
      ],
      "metadata": {
        "id": "RGFAdmxOe3Ag"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_responses_distribution(POPQUORN_0301, 'gpt-3.5-turbo-0301')\n",
        "get_responses_distribution(POPQUORN_0613, 'gpt-3.5-turbo-0613')"
      ],
      "metadata": {
        "id": "bDcgpVydiu9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listwise deletion of cases with invalid responses"
      ],
      "metadata": {
        "id": "c_8JkIdLllqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select rows with null values. via\n",
        "# https://stackoverflow.com/a/14247708\n",
        "todrop = POPQUORN_0301[POPQUORN_0301[POPQUORN_0301.columns[1:]].isna().any(axis=1)]['text'].tolist() + \\\n",
        "    POPQUORN_0613[POPQUORN_0613[POPQUORN_0613.columns[1:]].isna().any(axis=1)]['text'].tolist()\n",
        "# Drop rows where column values match any list element. via\n",
        "# https://stackoverflow.com/a/27965417\n",
        "POPQUORN_0301 = POPQUORN_0301[~POPQUORN_0301['text'].isin(todrop)]\n",
        "POPQUORN_0301.reset_index(drop=True, inplace=True)\n",
        "POPQUORN_0613 = POPQUORN_0613[~POPQUORN_0613['text'].isin(todrop)]\n",
        "POPQUORN_0613.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "pDSTxRFVI1ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save cleaned responses"
      ],
      "metadata": {
        "id": "g6p7gIjTmfRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POPQUORN_0301.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'POPQUORN_predictions_cleaned_gpt-3.5-turbo-0301.tsv',\n",
        "    sep='\\t', index=False)\n",
        "POPQUORN_0613.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'POPQUORN_predictions_cleaned_gpt-3.5-turbo-0613.tsv',\n",
        "    sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "FRyEON_YvKRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}