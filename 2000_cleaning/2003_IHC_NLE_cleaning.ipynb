{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "20fJ8J891X_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_FpuOpAXgqu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "id": "vDaPkpBkUdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "03IvRW_dUbFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create directory to store cleaned data"
      ],
      "metadata": {
        "id": "abdUibBQwtax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/datasets/cleaning', exist_ok=True)"
      ],
      "metadata": {
        "id": "uQBcyBOgwvLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets"
      ],
      "metadata": {
        "id": "EXHWFJW23GXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get lists of files in **/content/drive/MyDrive/datasets/IHC_NLE_gpt-3.5-turbo-0301** and **/content/drive/MyDrive/datasets/IHC_NLE_gpt-3.5-turbo-0613** directories"
      ],
      "metadata": {
        "id": "zUKZAIEwwlsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in directories. via\n",
        "# https://www.geeksforgeeks.org/python-list-files-in-a-directory/\n",
        "dir_0301 = '/content/drive/MyDrive/datasets/IHC_NLE_gpt-3.5-turbo-0301'\n",
        "file_list_0301 = os.listdir(dir_0301)\n",
        "file_list_0301 = sorted(file_list_0301)\n",
        "dir_0613 = '/content/drive/MyDrive/datasets/IHC_NLE_gpt-3.5-turbo-0613'\n",
        "file_list_0613 = os.listdir(dir_0613)\n",
        "file_list_0613 = sorted(file_list_0613)"
      ],
      "metadata": {
        "id": "ZP3sW0ri3i8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate files in file lists into one Pandas DataFrame for each list"
      ],
      "metadata": {
        "id": "tZv9VCG4w2nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and concatenate multiple files. via\n",
        "# https://stackoverflow.com/a/21232849\n",
        "IHC_NLE_0301 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0301, '/', file)), sep='\\t') for file in\n",
        "     file_list_0301],\n",
        "    axis=1)\n",
        "IHC_NLE_0613 = pd.concat(\n",
        "    [pd.read_csv(\"\".join((dir_0613, '/', file)), sep='\\t') for file in\n",
        "     file_list_0613],\n",
        "    axis=1)\n",
        "# Drop duplicate columns. via\n",
        "# https://www.geeksforgeeks.org/\n",
        "# how-to-find-drop-duplicate-columns-in-a-pandas-dataframe/\n",
        "IHC_NLE_0301 = IHC_NLE_0301.T.drop_duplicates().T\n",
        "IHC_NLE_0613 = IHC_NLE_0613.T.drop_duplicates().T"
      ],
      "metadata": {
        "id": "GF9argYz4E2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to remove responses indicating unsuccessful persona priming"
      ],
      "metadata": {
        "id": "sgzWfXV5scoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rm_failed(x):\n",
        "    if 'As an AI language model' in x:\n",
        "        return None\n",
        "    else:\n",
        "        return x"
      ],
      "metadata": {
        "id": "isn72ZC-stZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to extract possible JSON strings"
      ],
      "metadata": {
        "id": "hKI9S6SKvbqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get string between two substrings. via\n",
        "# https://www.geeksforgeeks.org/python-extract-string-between-two-substrings/\n",
        "def extract_JSON_like(x):\n",
        "    try:\n",
        "        return x[x.index('{\"'): x.index('\"}') + 2]\n",
        "    except (ValueError, AttributeError) as e:\n",
        "        return x"
      ],
      "metadata": {
        "id": "yQ9C1aBlvpNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to coerce strings into valid JSON strings"
      ],
      "metadata": {
        "id": "sru97jqIvtTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def coerce_JSON(x):\n",
        "    try:\n",
        "        json.loads(x)\n",
        "        return x\n",
        "    except ValueError:\n",
        "        return x.rsplit('tweet\": \"', 1)[0] + 'tweet\": \"' + \\\n",
        "            x.rsplit('tweet\": \"', 1)[1].replace('\"', '').replace('}', '') + \\\n",
        "            '\"}'\n",
        "    except TypeError:\n",
        "        return x"
      ],
      "metadata": {
        "id": "7Jyit6Mlv2Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to separate columns of valid JSON strings into `GROUP` and `implied statement of implicitly hateful tweet` columns"
      ],
      "metadata": {
        "id": "yyr3wWuUvLLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explode_JSON(df):\n",
        "    df.iloc[:, 4:] = df.iloc[:, 4:].applymap(lambda x: rm_failed(x))\n",
        "    df.iloc[:, 3:] = df.iloc[:, 3:].applymap(lambda x: extract_JSON_like(x))\n",
        "    df.iloc[:, 3:] = df.iloc[:, 3:].applymap(lambda x: coerce_JSON(x))\n",
        "    for i in df.columns[3:]:\n",
        "        # Flatten dictionary column. via\n",
        "        # https://stackoverflow.com/a/72947328\n",
        "        df = pd.concat([df, pd.json_normalize(\n",
        "            df[i].map(lambda x: eval(x) if pd.notnull(x) else x)).add_prefix(\n",
        "            i + '_')], axis=1)\n",
        "        df.pop(i)\n",
        "    for i in df.columns[3:]:\n",
        "        df.rename(columns={i: i.replace(' ', '_')}, inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "MRC0KJW1vE_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call the `explode_JSON` function"
      ],
      "metadata": {
        "id": "glUIe2QTwCWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IHC_NLE_0301 = explode_JSON(IHC_NLE_0301)\n",
        "IHC_NLE_0613 = explode_JSON(IHC_NLE_0613)"
      ],
      "metadata": {
        "id": "68QqKqmy_YEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listwise deletion of cases with invalid responses"
      ],
      "metadata": {
        "id": "kwmWjuYuIkTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select rows with null values. via\n",
        "# https://stackoverflow.com/a/14247708\n",
        "todrop = IHC_NLE_0301[IHC_NLE_0301.isnull().any(axis=1)]['post'].tolist()\n",
        "IHC_NLE_0301 = IHC_NLE_0301.dropna()\n",
        "IHC_NLE_0301.reset_index(drop=True, inplace=True)\n",
        "# Drop rows where column values match any list element. via\n",
        "# https://stackoverflow.com/a/27965417\n",
        "IHC_NLE_0613 = IHC_NLE_0613[~IHC_NLE_0613['post'].isin(todrop)]\n",
        "IHC_NLE_0613.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "_pkolTafIpWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save cleaned responses"
      ],
      "metadata": {
        "id": "kuQTfSpQyIzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IHC_NLE_0301.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'IHC_NLE_predictions_cleaned_gpt-3.5-turbo-0301.tsv',\n",
        "    sep='\\t', index=False)\n",
        "IHC_NLE_0613.to_csv(\n",
        "    '/content/drive/MyDrive/datasets/cleaning/'\n",
        "    'IHC_NLE_predictions_cleaned_gpt-3.5-turbo-0613.tsv',\n",
        "    sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "PePIwWsuOXDq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}