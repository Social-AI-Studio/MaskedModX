{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "LZcDrhRvqkuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For openai>=1.0.0, openai.ChatCompletion is not supported anymore. Install an earlier version. Install cohere and tiktoken to address the Error message that recently came up:\n",
        "<blockquote>ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.<br>\n",
        "llmx 0.0.15a0 requires cohere, which is not installed.<br>\n",
        "llmx 0.0.15a0 requires tiktoken, which is not installed.</blockquote>"
      ],
      "metadata": {
        "id": "u4kKSemLUn3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqBeYLjotxgQ"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.27.8 cohere tiktoken\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POb532mGMpDw"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "import os\n",
        "import dotenv\n",
        "import openai\n",
        "import pandas as pd\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "id": "xAatmbvOqx12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "49sblbzuqvBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create directories to store inferences"
      ],
      "metadata": {
        "id": "rrggcIOT9VUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/datasets/COVID-HATE_gpt-3.5-turbo-0301',\n",
        "            exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/datasets/COVID-HATE_gpt-3.5-turbo-0613',\n",
        "            exist_ok=True)"
      ],
      "metadata": {
        "id": "xAwp__RH9V7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authentication"
      ],
      "metadata": {
        "id": "CR1Syt2fqz-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have to first save your OpenAI API key in a .env file in your Google Drive, in the format:\n",
        "OPENAI_API_KEY = '...'."
      ],
      "metadata": {
        "id": "wNZ9gc75vzLO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzNMbn2uN065"
      },
      "outputs": [],
      "source": [
        "# OpenAI authentication on Google Colab. via\n",
        "# https://stackoverflow.com/a/77166086\n",
        "dotenv.load_dotenv('/content/drive/MyDrive/.env')\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset"
      ],
      "metadata": {
        "id": "FLKetCks3u-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VesFLoXN2_I"
      },
      "outputs": [],
      "source": [
        "annotated_tweets_w_text = pd.read_csv(\n",
        "    '/content/drive/MyDrive/datasets/annotated_tweets_w_text.csv')\n",
        "annotated_tweets_w_text = annotated_tweets_w_text.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set prompts"
      ],
      "metadata": {
        "id": "XRS4l-Ej_dYo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BHp6PaOOCfw"
      },
      "outputs": [],
      "source": [
        "def system_content(persona):\n",
        "    return inspect.cleandoc(\n",
        "        f\"\"\"From now on, act as {persona}.\n",
        "        Provide an answer that {persona} would regarding the tweet.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqV9aliDPeE3"
      },
      "outputs": [],
      "source": [
        "def user_content(tweet):\n",
        "    return inspect.cleandoc(f\"\"\"\n",
        "    I want you to perform a data annotation task. In your output, I want you\n",
        "    to return either “Hatespeech”, “Counterhate” or “Neutral”, depending on\n",
        "    whether you think the following tweet is an anti-Asian COVID-19 hate\n",
        "    tweet, a COVID-19 counterspeech tweet, or a neutral or irrelevant tweet.\n",
        "    A tweet is an anti-Asian COVID-19 hate tweet if you perceive that it is\n",
        "    antagonistic speech that is directed towards an Asian entity (individual\n",
        "    person, organization, or country), and others the Asian outgroup through\n",
        "    intentional opposition or hostility in the context of COVID-19. A tweet\n",
        "    is a COVID-19 counterspeech tweet if you perceive that it either: (a)\n",
        "    explicitly identifies, calls out, criticizes, condemns, challenges,\n",
        "    or opposes racism, hate, or violence towards an Asian entity or (b)\n",
        "    explicitly supports, expresses solidarity towards, or defends an Asian\n",
        "    entity. A tweet is neutral or irrelevant if it neither explicitly nor\n",
        "    implicitly conveys hate, nor counterspeech, but is related to COVID-19.\n",
        "    Tweets in this neutral category also include news, advertisements,\n",
        "    or outright spam. I want you to only respond with “Hatespeech”,\n",
        "    “Counterhate” or “Neutral”. Do not provide any other outputs or any\n",
        "    explanation for your output.\n",
        "\n",
        "    Tweet: \\\"\\\"\\\"\n",
        "    {tweet}\n",
        "    \\\"\\\"\\\"\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to call Chat Completion API with (persona) or without (no-persona default) the *system message*"
      ],
      "metadata": {
        "id": "jpLuDvU9BHlo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYDs7ZKjRTN1"
      },
      "outputs": [],
      "source": [
        "# Prevent rate limit errors. via\n",
        "# https://github.com/openai/openai-cookbook/blob/main/examples/\n",
        "# How_to_handle_rate_limits.ipynb\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def classifier_with_backoff(user_cont, model, system_cont=None):\n",
        "    if system_cont is None:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": user_cont}\n",
        "            ],\n",
        "            temperature=0,\n",
        "        )\n",
        "    else:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_cont},\n",
        "                {\"role\": \"user\", \"content\": user_cont}\n",
        "            ],\n",
        "            temperature=0,\n",
        "        )\n",
        "    return response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to perform model inference on **COVID-HATE**"
      ],
      "metadata": {
        "id": "bn_RhmfWBzcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function `predict_labels` that takes a list of personas (e.g., ['a White person in the United States', 'a Black or African American in the United States']), a `topic` (e.g., a sociodemographic attribute such as *Race/Nationality*), and a GPT model name (e.g., gpt-3.5-turbo-0301) as required input arguments. The optional argument `base` determines if annotations made by the no-persona default should be included. For each persona in the list of personas, the function iterates over each tweet in **COVID-HATE**, calling the function `classifier_with_backoff` for each tweet. It then adds the respective lists of labels predicted by each simulated persona as new columns to the **COVID-HATE** dataframe. The predicted labels are remapped to conform to how the data was originally coded in **COVID-HATE**, e.g., `0` if `Neutral`. The dataframe is saved in TSV file format, and the function returns the dataframe."
      ],
      "metadata": {
        "id": "IoFKLJo5KGSt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d7KQS46RoTW"
      },
      "outputs": [],
      "source": [
        "def predict_labels(persona_list, topic, model, base=None):\n",
        "    df = annotated_tweets_w_text.copy(deep=True)\n",
        "    tweets = df['Text'].values\n",
        "    if base == 'Yes':\n",
        "        df['predicted_labels_base'] = [\n",
        "            classifier_with_backoff(user_content(twt),\n",
        "                                    model) for twt in tweets]\n",
        "    for persona in persona_list:\n",
        "        df[f'predicted_labels_{persona}'.replace(' ', '_')] = [\n",
        "            classifier_with_backoff(user_content(twt),\n",
        "                                    model,\n",
        "                                    system_content(persona)) for twt in tweets]\n",
        "    # Remap predicted class labels. via\n",
        "    # https://stackoverflow.com/a/20250996\n",
        "    remap = {'Neutral': 0,\n",
        "             'Counterhate': 1,\n",
        "             'Hatespeech': 2}\n",
        "    for i in df.iloc[:, 3:].columns:\n",
        "        df.replace({i: remap}, inplace=True)\n",
        "    df.to_csv(\n",
        "        f'/content/drive/MyDrive/datasets/COVID-HATE_{model}/'\n",
        "        f'COVID-HATE_predictions_{topic}_{model}.tsv',\n",
        "        sep='\\t', index=False)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dictionaries, each with a `topic` as the key and a list of personas as the value"
      ],
      "metadata": {
        "id": "AiF7sCZq-c8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity, given the small number of personas considered, we do not segregate them at this point and use a single dictionary."
      ],
      "metadata": {
        "id": "gn27KirJ_Al3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDIkikR53xhj"
      },
      "outputs": [],
      "source": [
        "all = {\n",
        "    'all': ['a White person in the United States',\n",
        "            'a Black or African American in the United States',\n",
        "            'an American Indian or Alaska Native in the United States',\n",
        "            'an Asian in the United States',\n",
        "            'a Chinese person in the United States',\n",
        "            'a Native Hawaiian or Other Pacific Islander in the United States',\n",
        "            'a Chinese person in the People\\'s Republic of China',\n",
        "            'a Chinese undergraduate student in the United States',\n",
        "            'an Indian undergraduate student in the United States']}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call the `predict_labels` function"
      ],
      "metadata": {
        "id": "wpYur_kE_sAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running each of the following cells could take several hours. Colab Pro+ includes continuous code execution (capped at 24 hours) and background execution capabilities, enabling you to close your browser/device while your code runs. CPU is sufficient. Alternatively, you can download the notebooks and edit the code accordingly to point to the directories on your local machine you want to use."
      ],
      "metadata": {
        "id": "p6wagruJa1bA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RNetAs8HNL3"
      },
      "outputs": [],
      "source": [
        "predict_labels(list(all.values())[0],\n",
        "               list(all.keys())[0],\n",
        "               'gpt-3.5-turbo-0301',\n",
        "               'Yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puwZX956l_e7"
      },
      "outputs": [],
      "source": [
        "predict_labels(list(all.values())[0],\n",
        "               list(all.keys())[0],\n",
        "               'gpt-3.5-turbo-0613',\n",
        "               'Yes')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}