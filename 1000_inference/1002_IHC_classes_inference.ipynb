{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "hw_8I5QeMmqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For openai>=1.0.0, openai.ChatCompletion is not supported anymore. Install an earlier version. Install cohere and tiktoken to address the Error message that recently came up:\n",
        "<blockquote>ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.<br>\n",
        "llmx 0.0.15a0 requires cohere, which is not installed.<br>\n",
        "llmx 0.0.15a0 requires tiktoken, which is not installed.</blockquote>"
      ],
      "metadata": {
        "id": "PIQrFBxlMg7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqBeYLjotxgQ"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.27.8 cohere tiktoken\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POb532mGMpDw"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "import os\n",
        "import dotenv\n",
        "import openai\n",
        "import pandas as pd\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "id": "gzouBmV4M5iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "von6na4lM6-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create directories to store inferences"
      ],
      "metadata": {
        "id": "xjK-ml8pM-az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/datasets/IHC_classes_gpt-3.5-turbo-0301',\n",
        "            exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/datasets/IHC_classes_gpt-3.5-turbo-0613',\n",
        "            exist_ok=True)"
      ],
      "metadata": {
        "id": "Rdpr1wTEM-9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authentication"
      ],
      "metadata": {
        "id": "CNcXOdf5NgOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have to first save your OpenAI API key in a .env file in your Google Drive, in the format:\n",
        "OPENAI_API_KEY = '...'."
      ],
      "metadata": {
        "id": "-QbSS295Nhwz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzNMbn2uN065"
      },
      "outputs": [],
      "source": [
        "# OpenAI authentication on Google Colab. via\n",
        "# https://stackoverflow.com/a/77166086\n",
        "dotenv.load_dotenv('/content/drive/MyDrive/.env')\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset"
      ],
      "metadata": {
        "id": "TVLgbMRsNror"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VesFLoXN2_I"
      },
      "outputs": [],
      "source": [
        "implicit_hate_stg1_posts = pd.read_csv(\n",
        "    '/content/drive/MyDrive/datasets/implicit_hate_v1_stg1_posts.tsv',\n",
        "    sep='\\t')\n",
        "implicit_hate_stg1_posts = implicit_hate_stg1_posts.sample(n=2685,\n",
        "                                                           random_state=1)\n",
        "implicit_hate_stg1_posts = implicit_hate_stg1_posts.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set prompts"
      ],
      "metadata": {
        "id": "A4KhwZmJN2MM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BHp6PaOOCfw"
      },
      "outputs": [],
      "source": [
        "def system_content(persona):\n",
        "    return inspect.cleandoc(\n",
        "        f\"\"\"From now on, act as {persona}.\n",
        "        Provide an answer that {persona} would regarding the text.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqV9aliDPeE3"
      },
      "outputs": [],
      "source": [
        "def user_content(tweet):\n",
        "    return inspect.cleandoc(f\"\"\"Text: \\\"\\\"\\\"\n",
        "    {tweet}\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "    Does this text attack a person or a group of people, explicitly or\n",
        "    implicitly, based on their protected characteristics?\n",
        "\n",
        "    A: Yes, explicit hate speech\n",
        "    B: Yes, implicit hate speech\n",
        "    C: Not hate speech\n",
        "\n",
        "    Constraint: Answer with only the option above that is most accurate and\n",
        "    nothing else.\n",
        "\n",
        "    Tip: Explicit hate speech uses explicit hatred expressions or offensive\n",
        "    keywords such as n*gger, c*nt, etc. to attack a person or a group of\n",
        "    people based on their protected characteristics. Implicit hate speech is a\n",
        "    more complex attack on a person or a group of people without relying on\n",
        "    explicit keywords. Beware that implicit discriminatory speech may be\n",
        "    subtle. Protected characteristics include ethnicity, race, national origin,\n",
        "    religion, sex, gender, and sexual orientation. Note that pointing out\n",
        "    racism should not be considered as hate speech.\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to call Chat Completion API with (persona) or without (no-persona default) the *system message*"
      ],
      "metadata": {
        "id": "m6ZqSNNeOFm1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYDs7ZKjRTN1"
      },
      "outputs": [],
      "source": [
        "# Prevent rate limit errors. via\n",
        "# https://github.com/openai/openai-cookbook/blob/main/examples/\n",
        "# How_to_handle_rate_limits.ipynb\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def classifier_with_backoff(user_cont, model, system_cont=None):\n",
        "    if system_cont is None:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": user_cont}\n",
        "            ],\n",
        "            temperature=0,\n",
        "        )\n",
        "    else:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_cont},\n",
        "                {\"role\": \"user\", \"content\": user_cont}\n",
        "            ],\n",
        "            temperature=0,\n",
        "        )\n",
        "    return response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to perform model inference on **IHC**"
      ],
      "metadata": {
        "id": "E1oeGMkOPieX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function `predict_high_level_classes` that takes a list of personas (e.g., ['a White person', 'a Black or African American']), a `topic` (e.g., a sociodemographic attribute such as *Race/Ethnicity*), and a GPT model name (e.g., gpt-3.5-turbo-0301) as required input arguments. The optional argument `base` determines if annotations made by the no-persona default should be included. For each persona in the list of personas, the function iterates over each tweet in **IHC**, calling the function `classifier_with_backoff` for each tweet.  It then adds the respective lists of classes predicted by each simulated persona as new columns to the **IHC** dataframe. The predicted classes are remapped to conform to how the data was originally coded in **IHC**, e.g., `explicit_hate` if `A: Yes, explicit hate speech`. The dataframe is saved in TSV file format, and the function returns the dataframe."
      ],
      "metadata": {
        "id": "wbgMsEoOPlIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d7KQS46RoTW"
      },
      "outputs": [],
      "source": [
        "def predict_high_level_classes(persona_list, topic, model, base=None):\n",
        "    df = implicit_hate_stg1_posts.copy(deep=True)\n",
        "    tweets = df['post'].values\n",
        "    if base == 'Yes':\n",
        "        df['predicted_classes_base'] = [\n",
        "            classifier_with_backoff(user_content(twt),\n",
        "                                    model) for twt in tweets]\n",
        "    for persona in persona_list:\n",
        "        persona += ' in the United States'\n",
        "        df[f'predicted_classes_{persona}'.replace(' ', '_')] = [\n",
        "            classifier_with_backoff(user_content(twt),\n",
        "                                    model,\n",
        "                                    system_content(persona)) for twt in tweets]\n",
        "    # Remap predicted class labels. via\n",
        "    # https://stackoverflow.com/a/20250996\n",
        "    remap = {'A: Yes, explicit hate speech': 'explicit_hate',\n",
        "             'B: Yes, implicit hate speech': 'implicit_hate',\n",
        "             'C: Not hate speech': 'not_hate'}\n",
        "    for i in df.iloc[:, 2:].columns:\n",
        "        df.replace({i: remap}, inplace=True)\n",
        "    df.to_csv(\n",
        "        f'/content/drive/MyDrive/datasets/IHC_classes_{model}/'\n",
        "        f'IHC_classes_predictions_{topic}_{model}.tsv',\n",
        "        sep='\\t', index=False)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dictionaries, each with a `topic` as the key and a list of personas as the value"
      ],
      "metadata": {
        "id": "3HLmpUeZQaFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA2iGbtrELG8"
      },
      "outputs": [],
      "source": [
        "gender_genderidentity_sexuality = {\n",
        "    'gender_genderidentity_sexuality': ['a man',\n",
        "                                        'a woman',\n",
        "                                        'a non-binary person',\n",
        "                                        'a LGBTQIA+ person']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiYbc-Fq3nyC"
      },
      "outputs": [],
      "source": [
        "religion = {'religion': ['a Muslim',\n",
        "                         'an atheist',\n",
        "                         'a Buddhist',\n",
        "                         'a Christian',\n",
        "                         'a Hindu',\n",
        "                         'a Jew']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDIkikR53xhj"
      },
      "outputs": [],
      "source": [
        "race_ethnicity = {\n",
        "    'race_ethnicity': ['a White person',\n",
        "                       'a Black or African American',\n",
        "                       'an American Indian or Alaska Native',\n",
        "                       'an Asian',\n",
        "                       'a Native Hawaiian or Other Pacific Islander',\n",
        "                       'a Hispanic/Latinx person']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA-9Uh2J4JIK"
      },
      "outputs": [],
      "source": [
        "origin = {'origin': ['an immigrant',\n",
        "                     'a refugee',\n",
        "                     'an American citizen']}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call the `predict_high_level_classes` function"
      ],
      "metadata": {
        "id": "gL5WFrudQxL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running each of the following cells could take several hours. Colab Pro+ includes continuous code execution (capped at 24 hours) and background execution capabilities, enabling you to close your browser/device while your code runs. CPU is sufficient. Alternatively, you can download the notebooks and edit the code accordingly to point to the directories on your local machine you want to use."
      ],
      "metadata": {
        "id": "EnRtGBNNRCWS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlQv5l2Cm6Fr"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(gender_genderidentity_sexuality.values())[0],\n",
        "                           list(gender_genderidentity_sexuality.keys())[0],\n",
        "                           'gpt-3.5-turbo-0301',\n",
        "                           'Yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24rxV1fSeHRf"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(gender_genderidentity_sexuality.values())[0],\n",
        "                           list(gender_genderidentity_sexuality.keys())[0],\n",
        "                           'gpt-3.5-turbo-0613',\n",
        "                           'Yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP_ddRJYlMhI"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(religion.values())[0],\n",
        "                           list(religion.keys())[0],\n",
        "                           'gpt-3.5-turbo-0301')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UigakZ_lVpP"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(religion.values())[0],\n",
        "                           list(religion.keys())[0],\n",
        "                           'gpt-3.5-turbo-0613')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFI-2d6mlbDI"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(race_ethnicity.values())[0],\n",
        "                           list(race_ethnicity.keys())[0],\n",
        "                           'gpt-3.5-turbo-0301')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wYsnkaLlezw"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(race_ethnicity.values())[0],\n",
        "                           list(race_ethnicity.keys())[0],\n",
        "                           'gpt-3.5-turbo-0613')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLwUY9MOll2o"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(origin.values())[0],\n",
        "                           list(origin.keys())[0],\n",
        "                           'gpt-3.5-turbo-0301')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkYWq4iXlhsw"
      },
      "outputs": [],
      "source": [
        "predict_high_level_classes(list(origin.values())[0],\n",
        "                           list(origin.keys())[0],\n",
        "                           'gpt-3.5-turbo-0613')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}